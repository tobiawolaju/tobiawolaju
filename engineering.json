{
  "pageTitle": "Tobiloba Awolaju - Robotics Engineering Portfolio",
  "theme": "engineering",
  "profile": {
    "image": "pfp.jpg",
    "name": "Tobiloba Awolaju",
    "title": "Robotics Research Engineer | Perception, Control & Learning Systems",
    "bio": "<p style=\"font-size: large; padding-bottom: 3rem;\">Systems-level robotics engineer focused on perception, control, and learning for high-DOF robots. <br><br>I design and build end-to-end robotic systems—mechanics, control, sensing, and embedded AI—optimized for real-time performance and modularity. <br><br>Currently architecting a full-scale humanoid robot with AI-based state estimation and task execution. <br><br>I aim to develop intelligent, low-cost robotic systems that bridge research and practical applications.</p>",
    "resumeLink": "https://docs.google.com/document/d/1rAaz1npJsNaA1Z4rRAQerH271eRiXhrEhwdmj5DxFQg/edit?usp=sharing"
  },
  "sectionLabels": {
    "docs": "Technical Write-ups",
    "activity": "Git"
  },
  "filters": [
    {
      "id": "all",
      "label": "All"
    },
    {
      "id": "control",
      "label": "Control & Actuation"
    },
    {
      "id": "perception",
      "label": "Perception & SLAM"
    },
    {
      "id": "planning",
      "label": "Planning / Learning"
    },
    {
      "id": "embedded",
      "label": "Embedded Systems"
    }
  ],
  "projects": [
    {
      "category": "control",
      "image": "grey.jpg",
      "title": "Full-Body Humanoid (Control + Actuation) ↗",
      "description": "Low-cost, high-performance humanoid actuation featuring capstan-driven gimbal joints and hierarchical PID/MPC control.",
      "links": [
        {
          "text": "[3D Files]",
          "url": "#"
        },
        {
          "text": "[GitHub Repo]",
          "url": "#"
        },
        {
          "text": "[Demo Video]",
          "url": "#"
        },
        {
          "text": "[Docs]",
          "url": "#"
        }
      ],
      "writeup": {
        "motivation": "Designed a low-cost, high-DOF humanoid sleeve to test capstan-driven actuation and gimbal-jointed mechanics for scalable humanoid control.",
        "objectives": [
          "Enable 6 DOF per limb with smooth motion",
          "Maintain stability under ±10° perturbations",
          "Run on <50 W power budget",
          "Demonstrate integration with ROS2 planning stack"
        ],
        "architecture": "Hierarchical structure: ROS2 Gait Planner → PID Controller → Joint Encoders & Capstan Drives.",
        "hardware": "Capstan-driven gimbal joints for zero-backlash motion. Fusion 360 designed mechanics, optimized for weight/torque ratio.",
        "software": "Real-time PID control on firmware, integrated with MPC for gait stabilization in ROS2.",
        "perception": "Absolute magnetic encoders for state estimation; IMU integration for balance feedback.",
        "challenges": "Motor backlash compensated with high-tension capstan feedforward; custom PID tuning for low-cost actuators.",
        "results": "Measured <0.1° repeatability; successful 20-minute stability tests under perturbation.",
        "lessons": "Trade-off between mechanical complexity and control reliability; capstan drives provide superior stiffness.",
        "future": "Full-body bipedal locomotion integration and structural battery reinforcement.",
        "references": "Open-source ROS2 Control, EtherCAT protocols."
      }
    },
    {
      "category": "perception",
      "image": "grey.jpg",
      "title": "SLAM & Perception Stack ↗",
      "description": "Novel monocular SLAM system for high-DOF robots integrating camera, IMU, and AI-driven state estimation.",
      "links": [
        {
          "text": "[Docs]",
          "url": "#"
        },
        {
          "text": "[APK Demo]",
          "url": "#"
        },
        {
          "text": "[ESP32 Demo]",
          "url": "#"
        }
      ],
      "writeup": {
        "motivation": "Providing high-DOF robots with real-time mapping and localization using low-cost monocular sensors and compute.",
        "objectives": [
          "Enable real-time 3D mapping on edge devices",
          "Achieve <5cm drift over 100m trajectories",
          "Integrate monocular cues with IMU state estimation"
        ],
        "architecture": "Monocular Camera + IMU → AI-assisted Feature Extraction → State Estimation → Global Digital Twin.",
        "hardware": "ESP32-CAM and Android-based deployment for handheld testing and robot mounting.",
        "software": "Custom SLAM backend in C++ with learned depth priors for scale initialization.",
        "perception": "Hybrid signal processing: EKF-based IMU fusion + visual odometry.",
        "challenges": "IMU drift mitigation via optical flow integration and global loop closure.",
        "results": "Demonstrated real-time operation on mobile compute with high-DOF tracking accuracy.",
        "lessons": "The importance of robust scale recovery in monocular systems.",
        "future": "Multi-agent map stitching and multi-modal sensor fusion (Lidar/Sonar).",
        "references": "ORB-SLAM3, VINS-Mono documentation."
      }
    },
    {
      "category": "planning",
      "image": "grey.jpg",
      "title": "World Representation Engine / Planning ↗",
      "description": "Game-engine style digital twin with LLM-guided high-level task planning and force-aware motion abstraction.",
      "links": [
        {
          "text": "[Docs]",
          "url": "#"
        },
        {
          "text": "[Demo Video]",
          "url": "#"
        },
        {
          "text": "[Simulation]",
          "url": "#"
        }
      ],
      "writeup": {
        "motivation": "Bridging the gap between high-level LLM reasoning and low-level reactive control through a robust world model.",
        "objectives": [
          "Separate intelligence from low-level balance",
          "Implement action-token based task execution",
          "Enable time and force aware IK planning"
        ],
        "architecture": "LLM Planner → Action Token Parser → IK Engine → Digital Twin → Physical Robot.",
        "hardware": "Simulated in Gazebo/Webots; validated on humanoid sleeve hardware.",
        "software": "Kinematics engine with force constraints; Python-based LLM interface.",
        "perception": "World state represented as object-oriented entities; semantic scene understanding.",
        "challenges": "Synchronizing high-latency LLM decisions with real-time control constraints.",
        "results": "Autonomous multi-step task completion in semi-structured environments.",
        "lessons": "Abstraction layers are critical for scaling robotic intelligence.",
        "future": "Reinforcement learning for policy optimization within the world model.",
        "references": "MoveIt2, Transformer-based planning papers."
      }
    },
    {
      "category": "embedded",
      "image": "grey.jpg",
      "title": "Pebble-Sized Microscale Drone ↗",
      "description": "Extreme control and sensor fusion under severe size and power constraints for single-motor surveillance drones.",
      "links": [
        {
          "text": "[3D Files]",
          "url": "#"
        },
        {
          "text": "[GitHub Repo]",
          "url": "#"
        },
        {
          "text": "[Demo Video]",
          "url": "#"
        },
        {
          "text": "[Docs]",
          "url": "#"
        }
      ],
      "writeup": {
        "motivation": "Demonstrating engineering creativity and efficiency by achieving stable flight in a sub-50g drone platform.",
        "objectives": [
          "Maintain active stabilization at <30W power",
          "Implement sensor fusion on ultra-efficient compute",
          "Maximize flight endurance through weight optimization"
        ],
        "architecture": "Single-motor actuator → Embedded Control Loop → IMU Feedback → TinyCompute.",
        "hardware": "Custom PCB design; 3D printed ultra-lightweight chassis; efficient motor selection.",
        "software": "Firmware optimized for real-time constraints; efficient fixed-point math for control.",
        "perception": "Integrated IMU and optical flow for altitude and position hold.",
        "challenges": "Extreme power constraints requiring custom low-level PID tuning and efficient firmware.",
        "results": "Stable hover achieved; 8-minute flight time on minimal battery capacity.",
        "lessons": "Every gram and milliwatt matters in microscale robotics.",
        "future": "Autonomous swarm behaviors and integrated micro-cameras.",
        "references": "Crazyflie open-source firmware, KiCad design standards."
      }
    }
  ],
  "docs": [
    {
      "link": "#",
      "title": "Capstan-Driven Humanoid Control ↗",
      "description": "Deep dive into the mechanics and control of high-DOF humanoid joints."
    },
    {
      "link": "#",
      "title": "Real-Time SLAM on the Edge ↗",
      "description": "Technical analysis of monocular perception stacks for robotics."
    },
    {
      "link": "#",
      "title": "World Models for Robotics ↗",
      "description": "Integrating LLMs and IK for intelligent robot behavior."
    },
    {
      "link": "#",
      "title": "Microscale Embedded Systems ↗",
      "description": "Engineering for extreme efficiency in small-scale robotics."
    }
  ]
}